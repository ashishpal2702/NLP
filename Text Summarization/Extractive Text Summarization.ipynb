{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Kathmandu, Nepal (CNN) -- A ferocious leopard may have killed 15 people in Nepal in a 15-month span, its latest victim a 4-year-old boy that the creature dragged away into the jungle to eat.\n",
    "\n",
    "The head of boy was found in the forest a kilometer from his home Saturday morning, said Kamal Prasad Kharel, the police chief of the Baitadi district, an area about 600 kilometers (373 miles) west of Kathmandu.\n",
    "\n",
    "The grisly discovery, which came after teams of people searched for the child, marks the 15th victim in the past 15 months in that remote district in western Nepal.\n",
    "\n",
    "The police chief suspects that a single man-eating leopard is responsible for the deaths. If not, there are at most two of the man-eating creatures around, he believes.\n",
    "\n",
    "Maheshwor Dhakal, an ecologist at the Department of National Parks and Wildlife Conservation in Kathmandu, agreed that it is unusual to find more than one or two man-eating animals in one area. Most leopards live on wild prey.\n",
    "\n",
    "More human victims could also be expected if there were more than one or two man-eaters around, he said.\n",
    "\n",
    "\"Since human blood has more salt than animal blood, once wild animals get the taste of salty blood they do not like other animals like deer,\" Dhakal said.\n",
    "\n",
    "Kharel said he feared the actual number of people killed by the leopard could be higher than 15, because others have lost their life to leopard attacks in Uttarkhand state in northern India, which borders Baitadi district.\n",
    "\n",
    "\"It could be the same leopard,\" he said.\n",
    "\n",
    "Of the 15 victims in Nepal so far, two-thirds are children below the age of 10. The others are older children and a 29-year-old woman who had gone to collect fodder for domestic animals in the nearby forest, a common practice in Nepal.\n",
    "\n",
    "\"No adult male has been killed,\" Kharel said.\n",
    "\n",
    "All the victims are from villages bordering the dense forests in the district, he said.\n",
    "\n",
    "After killing its victim, the leopard takes the body away into the forest to eat.\n",
    "\n",
    "\"In the case of the children it just leaves behind the head, eating everything, but some parts of the adult body are left behind because it cannot finish it,\" Kharel added.\n",
    "\n",
    "The district administration has announced a Rs. 25,000 (about $300) reward to anyone who captures or kills the leopard.\n",
    "\n",
    "The local administration has sought to raise public awareness of the dangers of going alone into nearby forests and has mobilized the police, armed police force and local people who have licensed guns to hunt for the animal.\n",
    "\n",
    "Controlling this particular leopard has been a challenge for the wildlife officials in Kathmandu.\n",
    "\n",
    "\"We are sending a veterinary doctor to the district to understand the situation,\" Dhakal, the ecologist, said. \"There is no alternative but to kill the leopard.\"\n",
    "\n",
    "The chief district administrator has granted permission for this particular leopard to be killed. Normally, it is illegal to kill wild animals.\n",
    "\n",
    "Leopards are common in the low mountain areas, as compared to the high Himalayas, across the country.\n",
    "\n",
    "While cases of leopards killing domestic animals are common, and there are sometimes instances of leopards killing people in Nepal, this case is \"extreme,\" Dhakal said.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from contractions import CONTRACTION_MAP\n",
    "CONTRACTION_MAP = {\n",
    "\"ain't\": \"is not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from html.parser import HTMLParser\n",
    "import unicodedata\n",
    "\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "wnl = WordNetLemmatizer()\n",
    "html_parser = HTMLParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text\n",
    "def tokenize_text(text):\n",
    "    tokens = nltk.word_tokenize(text) \n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contract Text -> Converting in standard English Words - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text, contraction_mapping):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging -> Tag words using English Grammar characteristics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "def pos_tag_text(text):\n",
    "    \n",
    "    def penn_to_wn_tags(pos_tag):\n",
    "        if pos_tag.startswith('J'):\n",
    "            return wn.ADJ\n",
    "        elif pos_tag.startswith('V'):\n",
    "            return wn.VERB\n",
    "        elif pos_tag.startswith('N'):\n",
    "            return wn.NOUN\n",
    "        elif pos_tag.startswith('R'):\n",
    "            return wn.ADV\n",
    "        else:\n",
    "            return None\n",
    "    words = tokenize_text(text)\n",
    "    tagged_text = nltk.pos_tag(words)\n",
    "    tagged_lower_text = [(word.lower(), penn_to_wn_tags(pos_tag))\n",
    "                         for word, pos_tag in\n",
    "                         tagged_text]\n",
    "    return tagged_lower_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    \n",
    "    pos_tagged_text = pos_tag_text(text)\n",
    "    lemmatized_tokens = [wnl.lemmatize(word, pos_tag) if pos_tag\n",
    "                         else word                     \n",
    "                         for word, pos_tag in pos_tagged_text]\n",
    "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    tokens = tokenize_text(text)\n",
    "    pattern = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
    "    filtered_tokens = filter(None, [pattern.sub(' ', token) for token in tokens])\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    tokens = tokenize_text(text)\n",
    "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unescape_html(parser, text):\n",
    "    \n",
    "    return parser.unescape(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Normalize Text Corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize_corpus(corpus, lemmatize=False, tokenize=False):\n",
    "    \n",
    "    normalized_corpus = [] \n",
    "    \n",
    "    for text in corpus:\n",
    "        text = html_parser.unescape(text)\n",
    "        text = expand_contractions(text, CONTRACTION_MAP)\n",
    "        if lemmatize:\n",
    "            text = lemmatize_text(text)\n",
    "        else:\n",
    "            text = text.lower()\n",
    "        text = remove_special_characters(text)\n",
    "        text = remove_stopwords(text)\n",
    "        #print(text)\n",
    "        if tokenize:\n",
    "            text = tokenize_text(text)\n",
    "            #print(text)\n",
    "            #normalized_corpus = normalized_corpus.join(text)\n",
    "            normalized_corpus.append(text)\n",
    "        else:\n",
    "            #normalized_corpus = normalized_corpus.join(text)\n",
    "            normalized_corpus.append(text)\n",
    "            \n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse document - > Return Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_document(document):\n",
    "    document = re.sub('\\n', ' ', document)\n",
    "    if isinstance(document, str):\n",
    "        document = document\n",
    "    elif isinstance(document, unicode):\n",
    "        return unicodedata.normalize('NFKD', document).encode('ascii', 'ignore')\n",
    "    else:\n",
    "        raise ValueError('Document is not string or unicode!')\n",
    "    document = document.strip()\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    sentences = [sentence.strip() for sentence in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kathmandu, Nepal (CNN) -- A ferocious leopard may have killed 15 people in Nepal in a 15-month span, its latest victim a 4-year-old boy that the creature dragged away into the jungle to eat.', 'The head of boy was found in the forest a kilometer from his home Saturday morning, said Kamal Prasad Kharel, the police chief of the Baitadi district, an area about 600 kilometers (373 miles) west of Kathmandu.', 'The grisly discovery, which came after teams of people searched for the child, marks the 15th victim in the past 15 months in that remote district in western Nepal.', 'The police chief suspects that a single man-eating leopard is responsible for the deaths.', 'If not, there are at most two of the man-eating creatures around, he believes.', 'Maheshwor Dhakal, an ecologist at the Department of National Parks and Wildlife Conservation in Kathmandu, agreed that it is unusual to find more than one or two man-eating animals in one area.', 'Most leopards live on wild prey.', 'More human victims could also be expected if there were more than one or two man-eaters around, he said.', '\"Since human blood has more salt than animal blood, once wild animals get the taste of salty blood they do not like other animals like deer,\" Dhakal said.', 'Kharel said he feared the actual number of people killed by the leopard could be higher than 15, because others have lost their life to leopard attacks in Uttarkhand state in northern India, which borders Baitadi district.', '\"It could be the same leopard,\" he said.', 'Of the 15 victims in Nepal so far, two-thirds are children below the age of 10.', 'The others are older children and a 29-year-old woman who had gone to collect fodder for domestic animals in the nearby forest, a common practice in Nepal.', '\"No adult male has been killed,\" Kharel said.', 'All the victims are from villages bordering the dense forests in the district, he said.', 'After killing its victim, the leopard takes the body away into the forest to eat.', '\"In the case of the children it just leaves behind the head, eating everything, but some parts of the adult body are left behind because it cannot finish it,\" Kharel added.', 'The district administration has announced a Rs.', '25,000 (about $300) reward to anyone who captures or kills the leopard.', 'The local administration has sought to raise public awareness of the dangers of going alone into nearby forests and has mobilized the police, armed police force and local people who have licensed guns to hunt for the animal.', 'Controlling this particular leopard has been a challenge for the wildlife officials in Kathmandu.', '\"We are sending a veterinary doctor to the district to understand the situation,\" Dhakal, the ecologist, said.', '\"There is no alternative but to kill the leopard.\"', 'The chief district administrator has granted permission for this particular leopard to be killed.', 'Normally, it is illegal to kill wild animals.', 'Leopards are common in the low mountain areas, as compared to the high Himalayas, across the country.', 'While cases of leopards killing domestic animals are common, and there are sometimes instances of leopards killing people in Nepal, this case is \"extreme,\" Dhakal said.']\n"
     ]
    }
   ],
   "source": [
    "sentences = parse_document(text)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Anaconda5\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: The unescape method is deprecated and will be removed in 3.5, use html.unescape() instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kathmandu nepal cnn ferocious leopard may kill 15 people nepal 15 month span late victim 4 year old boy creature drag away jungle eat', 'head boy find forest kilometer home saturday morning say kamal prasad kharel police chief baitadi district area 600 kilometer 373 mile west kathmandu', 'grisly discovery come team people search child mark 15th victim past 15 month remote district western nepal', 'police chief suspect single man eating leopard responsible death', 'two man eating creature around believe', 'maheshwor dhakal ecologist department national park wildlife conservation kathmandu agree unusual find one two man eating animal one area', 'leopard live wild prey', 'human victim could also expect one two man eater around say', 'since human blood salt animal blood wild animal get taste salty blood like animal like deer dhakal say', 'kharel say fear actual number people kill leopard could high 15 others lose life leopard attack uttarkhand state northern india border baitadi district', 'could leopard say', '15 victim nepal far two thirds child age 10', 'others old child 29 year old woman go collect fodder domestic animal nearby forest common practice nepal', 'adult male kill kharel say', 'victim village border dense forest district say', 'kill victim leopard take body away forest eat', 'case child leave behind head eat everything part adult body leave behind finish kharel add', 'district administration announce r', '25 000 300 reward anyone capture kill leopard', 'local administration seek raise public awareness danger go alone nearby forest mobilize police arm police force local people license gun hunt animal', 'control particular leopard challenge wildlife official kathmandu', 'send veterinary doctor district understand situation dhakal ecologist say', 'alternative kill leopard', 'chief district administrator grant permission particular leopard kill', 'normally illegal kill wild animal', 'leopard common low mountain area compare high himalaya across country', 'case leopard kill domestic animal common sometimes instance leopard kill people nepal case extreme dhakal say']\n"
     ]
    }
   ],
   "source": [
    "norm_sentences = normalize_corpus(sentences, True)\n",
    "print(norm_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sententces in Document: 27\n"
     ]
    }
   ],
   "source": [
    "total_sentences = len(norm_sentences)\n",
    "print( 'Total Sententces in Document:', total_sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils import build_feature_matrix, low_rank_svd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def build_feature_matrix(documents, feature_type='frequency'):\n",
    "\n",
    "    feature_type = feature_type.lower().strip()  \n",
    "    \n",
    "    if feature_type == 'binary':\n",
    "        vectorizer = CountVectorizer(binary=True, min_df=1, \n",
    "                                     ngram_range=(1, 1))\n",
    "    elif feature_type == 'frequency':\n",
    "        vectorizer = CountVectorizer(binary=False, min_df=1, \n",
    "                                     ngram_range=(1, 1))\n",
    "    elif feature_type == 'tfidf':\n",
    "        vectorizer = TfidfVectorizer(min_df=1, \n",
    "                                     ngram_range=(1, 1))\n",
    "    else:\n",
    "        raise Exception(\"Wrong feature type entered. Possible values: 'binary', 'frequency', 'tfidf'\")\n",
    "\n",
    "    feature_matrix = vectorizer.fit_transform(documents).astype(float)\n",
    "    \n",
    "    return vectorizer, feature_matrix\n",
    "\n",
    "\n",
    "from scipy.sparse.linalg import svds\n",
    "    \n",
    "def low_rank_svd(matrix, singular_count=2):\n",
    "    \n",
    "    u, s, vt = svds(matrix, k=singular_count)\n",
    "    return u, s, vt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking TOP Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.49 5.24 5.1  2.03 1.4  2.73 0.05 0.49 1.65 3.86 1.14 2.84 3.16 0.32\n",
      " 3.07 2.9  4.89 0.97 1.17 5.3  1.45 3.09 1.15 1.48 0.38 3.04 1.89]\n",
      "[ 1  2 19]\n",
      "The head of boy was found in the forest a kilometer from his home Saturday morning, said Kamal Prasad Kharel, the police chief of the Baitadi district, an area about 600 kilometers (373 miles) west of Kathmandu.\n",
      "The grisly discovery, which came after teams of people searched for the child, marks the 15th victim in the past 15 months in that remote district in western Nepal.\n",
      "The local administration has sought to raise public awareness of the dangers of going alone into nearby forests and has mobilized the police, armed police force and local people who have licensed guns to hunt for the animal.\n"
     ]
    }
   ],
   "source": [
    "num_sentences = 3\n",
    "num_topics = 2\n",
    "\n",
    "vec, dt_matrix = build_feature_matrix(sentences, \n",
    "                                      feature_type='frequency')\n",
    "\n",
    "td_matrix = dt_matrix.transpose()\n",
    "td_matrix = td_matrix.multiply(td_matrix > 0)\n",
    "\n",
    "u, s, vt = low_rank_svd(td_matrix, singular_count=num_topics)  \n",
    "                                         \n",
    "sv_threshold = 0.5\n",
    "min_sigma_value = max(s) * sv_threshold\n",
    "s[s < min_sigma_value] = 0\n",
    "\n",
    "salience_scores = np.sqrt(np.dot(np.square(s), np.square(vt)))\n",
    "print( np.round(salience_scores, 2))\n",
    "\n",
    "top_sentence_indices = salience_scores.argsort()[-num_sentences:][::-1]\n",
    "top_sentence_indices.sort()\n",
    "print (top_sentence_indices)\n",
    "\n",
    "for index in top_sentence_indices:\n",
    "    print (sentences[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.   0.07 0.24 0.02 0.09 0.03 0.03 0.04 0.   0.13 0.05 0.23 0.2  0.04\n",
      "  0.05 0.26 0.04 0.   0.05 0.02 0.08 0.   0.1  0.05 0.04 0.02 0.17]\n",
      " [0.07 1.   0.02 0.11 0.   0.11 0.   0.02 0.01 0.11 0.06 0.   0.03 0.11\n",
      "  0.12 0.05 0.07 0.06 0.   0.08 0.05 0.06 0.   0.1  0.   0.05 0.02]\n",
      " [0.24 0.02 1.   0.   0.   0.   0.   0.04 0.   0.09 0.   0.21 0.07 0.\n",
      "  0.1  0.05 0.04 0.07 0.   0.03 0.   0.04 0.   0.04 0.   0.   0.08]\n",
      " [0.02 0.11 0.   1.   0.22 0.12 0.05 0.08 0.   0.04 0.08 0.   0.   0.\n",
      "  0.   0.04 0.   0.   0.04 0.11 0.04 0.   0.07 0.15 0.   0.03 0.05]\n",
      " [0.09 0.   0.   0.22 1.   0.21 0.   0.33 0.   0.   0.   0.1  0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.03 0.11 0.   0.12 0.21 1.   0.   0.24 0.09 0.   0.   0.05 0.03 0.\n",
      "  0.   0.   0.   0.   0.   0.02 0.14 0.13 0.   0.   0.06 0.06 0.07]\n",
      " [0.03 0.   0.   0.05 0.   0.   1.   0.   0.08 0.07 0.13 0.   0.   0.\n",
      "  0.   0.06 0.   0.   0.05 0.   0.06 0.   0.11 0.06 0.21 0.05 0.08]\n",
      " [0.04 0.02 0.04 0.08 0.33 0.24 0.   1.   0.08 0.08 0.31 0.14 0.   0.06\n",
      "  0.13 0.07 0.   0.   0.   0.   0.   0.04 0.   0.   0.   0.   0.03]\n",
      " [0.   0.01 0.   0.   0.   0.09 0.08 0.08 1.   0.01 0.06 0.   0.07 0.04\n",
      "  0.03 0.   0.   0.   0.   0.05 0.   0.07 0.   0.   0.21 0.   0.12]\n",
      " [0.13 0.11 0.09 0.04 0.   0.   0.07 0.08 0.01 1.   0.31 0.05 0.05 0.16\n",
      "  0.17 0.09 0.03 0.06 0.07 0.02 0.05 0.06 0.15 0.12 0.04 0.1  0.16]\n",
      " [0.05 0.06 0.   0.08 0.   0.   0.13 0.31 0.06 0.31 1.   0.   0.   0.16\n",
      "  0.14 0.1  0.   0.   0.08 0.   0.09 0.11 0.17 0.09 0.   0.07 0.21]\n",
      " [0.23 0.   0.21 0.   0.1  0.05 0.   0.14 0.   0.05 0.   1.   0.11 0.\n",
      "  0.08 0.08 0.05 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.05]\n",
      " [0.2  0.03 0.07 0.   0.   0.03 0.   0.   0.07 0.05 0.   0.11 1.   0.\n",
      "  0.06 0.06 0.04 0.   0.   0.14 0.   0.   0.   0.   0.06 0.06 0.18]\n",
      " [0.04 0.11 0.   0.   0.   0.   0.   0.06 0.04 0.16 0.16 0.   0.   1.\n",
      "  0.09 0.08 0.19 0.   0.07 0.   0.   0.07 0.15 0.08 0.1  0.   0.16]\n",
      " [0.05 0.12 0.1  0.   0.   0.   0.   0.13 0.03 0.17 0.14 0.08 0.06 0.09\n",
      "  1.   0.2  0.   0.12 0.   0.05 0.   0.12 0.   0.08 0.   0.   0.04]\n",
      " [0.26 0.05 0.05 0.04 0.   0.   0.06 0.07 0.   0.09 0.1  0.08 0.06 0.08\n",
      "  0.2  1.   0.16 0.   0.1  0.05 0.05 0.   0.2  0.11 0.08 0.04 0.15]\n",
      " [0.04 0.07 0.04 0.   0.   0.   0.   0.   0.   0.03 0.   0.05 0.04 0.19\n",
      "  0.   0.16 1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.11]\n",
      " [0.   0.06 0.07 0.   0.   0.   0.   0.   0.   0.06 0.   0.   0.   0.\n",
      "  0.12 0.   0.   1.   0.   0.11 0.   0.1  0.   0.11 0.   0.   0.  ]\n",
      " [0.05 0.   0.   0.04 0.   0.   0.05 0.   0.   0.07 0.08 0.   0.   0.07\n",
      "  0.   0.1  0.   0.   1.   0.   0.04 0.   0.17 0.09 0.07 0.03 0.12]\n",
      " [0.02 0.08 0.03 0.11 0.   0.02 0.   0.   0.05 0.02 0.   0.   0.14 0.\n",
      "  0.05 0.05 0.   0.11 0.   1.   0.   0.   0.   0.   0.05 0.   0.06]\n",
      " [0.08 0.05 0.   0.04 0.   0.14 0.06 0.   0.   0.05 0.09 0.   0.   0.\n",
      "  0.   0.05 0.   0.   0.04 0.   1.   0.   0.08 0.19 0.   0.04 0.06]\n",
      " [0.   0.06 0.04 0.   0.   0.13 0.   0.04 0.07 0.06 0.11 0.   0.   0.07\n",
      "  0.12 0.   0.   0.1  0.   0.   0.   1.   0.   0.06 0.   0.   0.09]\n",
      " [0.1  0.   0.   0.07 0.   0.   0.11 0.   0.   0.15 0.17 0.   0.   0.15\n",
      "  0.   0.2  0.   0.   0.17 0.   0.08 0.   1.   0.19 0.14 0.07 0.25]\n",
      " [0.05 0.1  0.04 0.15 0.   0.   0.06 0.   0.   0.12 0.09 0.   0.   0.08\n",
      "  0.08 0.11 0.   0.11 0.09 0.   0.19 0.06 0.19 1.   0.07 0.04 0.14]\n",
      " [0.04 0.   0.   0.   0.   0.06 0.21 0.   0.21 0.04 0.   0.   0.06 0.1\n",
      "  0.   0.08 0.   0.   0.07 0.05 0.   0.   0.14 0.07 1.   0.   0.16]\n",
      " [0.02 0.05 0.   0.03 0.   0.06 0.05 0.   0.   0.1  0.07 0.   0.06 0.\n",
      "  0.   0.04 0.   0.   0.03 0.   0.04 0.   0.07 0.04 0.   1.   0.11]\n",
      " [0.17 0.02 0.08 0.05 0.   0.07 0.08 0.03 0.12 0.16 0.21 0.05 0.18 0.16\n",
      "  0.04 0.15 0.11 0.   0.12 0.06 0.06 0.09 0.25 0.14 0.16 0.11 1.  ]]\n",
      "[9, 10, 26]\n",
      "Kharel said he feared the actual number of people killed by the leopard could be higher than 15, because others have lost their life to leopard attacks in Uttarkhand state in northern India, which borders Baitadi district.\n",
      "\"It could be the same leopard,\" he said.\n",
      "While cases of leopards killing domestic animals are common, and there are sometimes instances of leopards killing people in Nepal, this case is \"extreme,\" Dhakal said.\n"
     ]
    }
   ],
   "source": [
    "import networkx\n",
    "\n",
    "num_sentences = 3\n",
    "vec, dt_matrix = build_feature_matrix(norm_sentences, feature_type='tfidf')\n",
    "similarity_matrix = (dt_matrix * dt_matrix.T)\n",
    "print (np.round(similarity_matrix.todense(), 2))\n",
    "\n",
    "similarity_graph = networkx.from_scipy_sparse_matrix(similarity_matrix)\n",
    "\n",
    "networkx.draw_networkx(similarity_graph)\n",
    "\n",
    "scores = networkx.pagerank(similarity_graph)\n",
    "\n",
    "ranked_sentences = sorted(((score, index) \n",
    "                            for index, score \n",
    "                            in scores.items()), \n",
    "                          reverse=True)\n",
    "ranked_sentences\n",
    "\n",
    "top_sentence_indices = [ranked_sentences[index][1] \n",
    "                        for index in range(num_sentences)]\n",
    "top_sentence_indices.sort()\n",
    "print (top_sentence_indices)\n",
    "\n",
    "for index in top_sentence_indices:\n",
    "    print (sentences[index])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsa_text_summarizer(documents,sen, num_sentences=2,\n",
    "                        num_topics=2, feature_type='frequency',\n",
    "                        sv_threshold=0.5):\n",
    "                            \n",
    "    vec, dt_matrix = build_feature_matrix(documents, \n",
    "                                          feature_type=feature_type)\n",
    "\n",
    "    td_matrix = dt_matrix.transpose()\n",
    "    td_matrix = td_matrix.multiply(td_matrix > 0)\n",
    "\n",
    "    u, s, vt = low_rank_svd(td_matrix, singular_count=num_topics)  \n",
    "    min_sigma_value = max(s) * sv_threshold\n",
    "    s[s < min_sigma_value] = 0\n",
    "    \n",
    "    salience_scores = np.sqrt(np.dot(np.square(s), np.square(vt)))\n",
    "    top_sentence_indices = salience_scores.argsort()[-num_sentences:][::-1]\n",
    "    top_sentence_indices.sort()\n",
    "    summ = list()\n",
    "    for index in top_sentence_indices:\n",
    "        #print (sen[index])\n",
    "        summ.append(sen[index])\n",
    "    return summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textrank_text_summarizer(documents,sen , num_sentences=2,\n",
    "                             feature_type='frequency'):\n",
    "    \n",
    "    vec, dt_matrix = build_feature_matrix(norm_sentences, \n",
    "                                      feature_type='tfidf')\n",
    "    similarity_matrix = (dt_matrix * dt_matrix.T)\n",
    "        \n",
    "    similarity_graph = networkx.from_scipy_sparse_matrix(similarity_matrix)\n",
    "    scores = networkx.pagerank(similarity_graph)   \n",
    "    \n",
    "    ranked_sentences = sorted(((score, index) \n",
    "                                for index, score \n",
    "                                in scores.items()), \n",
    "                              reverse=True)\n",
    "\n",
    "    top_sentence_indices = [ranked_sentences[index][1] \n",
    "                            for index in range(num_sentences)]\n",
    "    top_sentence_indices.sort()\n",
    "    summ = list()\n",
    "    for index in top_sentence_indices:\n",
    "        #print( sen[index] )\n",
    "        summ.append(sen[index])\n",
    "    return summ    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kathmandu, Nepal (CNN) -- A ferocious leopard may have killed 15 people in Nepal in a 15-month span, its latest victim a 4-year-old boy that the creature dragged away into the jungle to eat.',\n",
       " '\"Since human blood has more salt than animal blood, once wild animals get the taste of salty blood they do not like other animals like deer,\" Dhakal said.',\n",
       " 'The local administration has sought to raise public awareness of the dangers of going alone into nearby forests and has mobilized the police, armed police force and local people who have licensed guns to hunt for the animal.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = lsa_text_summarizer(documents = norm_sentences, sen = sentences ,num_sentences=3,\n",
    "                    num_topics=5, feature_type='frequency')  \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kharel said he feared the actual number of people killed by the leopard could be higher than 15, because others have lost their life to leopard attacks in Uttarkhand state in northern India, which borders Baitadi district.',\n",
       " '\"It could be the same leopard,\" he said.',\n",
       " 'While cases of leopards killing domestic animals are common, and there are sometimes instances of leopards killing people in Nepal, this case is \"extreme,\" Dhakal said.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = textrank_text_summarizer(documents = norm_sentences, sen = sentences, num_sentences=3,\n",
    "                         feature_type='tfidf') \n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct News Summarization using genism -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Anaconda5\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.summarization import summarize, keywords\n",
    "\n",
    "def text_summarization_gensim(text, summary_ratio=0.5):\n",
    "    \n",
    "    summary = summarize(text, split=True, ratio=summary_ratio)\n",
    "    summ = list()\n",
    "    for sentence in summary:\n",
    "        #print(sentence)\n",
    "        summ.append(sentence)\n",
    "    return summ    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kathmandu, Nepal (CNN) -- A ferocious leopard may have killed 15 people in Nepal in a 15-month span, its latest victim a 4-year-old boy that the creature dragged away into the jungle to eat.',\n",
       " 'The head of boy was found in the forest a kilometer from his home Saturday morning, said Kamal Prasad Kharel, the police chief of the Baitadi district, an area about 600 kilometers (373 miles) west of Kathmandu.',\n",
       " 'The police chief suspects that a single man-eating leopard is responsible for the deaths.',\n",
       " 'Maheshwor Dhakal, an ecologist at the Department of National Parks and Wildlife Conservation in Kathmandu, agreed that it is unusual to find more than one or two man-eating animals in one area.',\n",
       " 'Kharel said he feared the actual number of people killed by the leopard could be higher than 15, because others have lost their life to leopard attacks in Uttarkhand state in northern India, which borders Baitadi district.',\n",
       " 'The others are older children and a 29-year-old woman who had gone to collect fodder for domestic animals in the nearby forest, a common practice in Nepal.',\n",
       " 'All the victims are from villages bordering the dense forests in the district, he said.',\n",
       " 'After killing its victim, the leopard takes the body away into the forest to eat.',\n",
       " 'The chief district administrator has granted permission for this particular leopard to be killed.',\n",
       " 'While cases of leopards killing domestic animals are common, and there are sometimes instances of leopards killing people in Nepal, this case is \"extreme,\" Dhakal said.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = text_summarization_gensim(text,0.4)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
